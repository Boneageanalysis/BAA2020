# -*- coding: utf-8 -*-
"""incept (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cLdYlojvy31zd4NDbBN-_uuUUoG2LzK7
"""

# Commented out IPython magic to ensure Python compatibility.

"""# New Section"""

from keras.models import Model
from keras_preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout, BatchNormalization
from keras.layers import Input, Conv2D, multiply, LocallyConnected2D, Lambda, Flatten, concatenate
from keras.layers import GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from keras import optimizers
from keras.optimizers import SGD, Adam
from keras.metrics import mean_absolute_error
from keras.applications import VGG16,InceptionV3
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import os
import matplotlib.pyplot as plt
import seaborn as sns

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # showing and rendering figures
# io related
#from skimage.io import imread
import os
from glob import glob
import seaborn as sns
from sklearn.model_selection import train_test_split
# not needed in Kaggle, but required in Jupyter
# %matplotlib inline

# hyperparameters
EPOCHS = 10
LEARNING_RATE = 0.006
BATCH_SIZE_TRAIN = 32
BATCH_SIZE_VAL = 256

#image parameters 
PIXELS = 299#default for Xception
CHANNELS = 3
IMG_SIZE = (PIXELS, PIXELS)
IMG_DIMS = (PIXELS, PIXELS, CHANNELS)
VALIDATION_FRACTION = 0.1
SEED = 7834

import pandas as pd
csvfile='H:\\boneage\\BAA\\boneage-training-dataset-mask (1).csv'
df = pd.read_csv(csvfile)

#df = pd.read_csv('C:\\Users\\darugar\\Desktop\\ml\\bone\\boneage-training-dataset.csv')


files = ['H:/boneage/BAA/masked images/' + str(i) + '.png' for i in df['id']]
df['file'] = files
df['exists'] = df['file'].map(os.path.exists)

print(df)

fig, ax = plt.subplots()
ax = sns.distplot(df['boneage'], bins=10)
ax.set(xlabel='Boneage (months)', ylabel='Density',
    title='Boneage distribution');

boneage_mean = df['boneage'].mean()#mean age
boneage_div = 2*df['boneage'].std()
print(boneage_mean,"  ",boneage_div)
df['boneage_zscore'] = df['boneage'].map(lambda x:
    (x - boneage_mean) / boneage_div)
df.dropna(inplace=True)

df['gender'] = df['male'].map(lambda x: 1 if x else 0)

df['boneage_category'] = pd.cut(df['boneage'], 10)

df['gender']
df['boneage_category']
print(df)

raw_train_df, raw_valid_df = train_test_split(df, test_size=VALIDATION_FRACTION,
  random_state=2018)

raw_train_df.shape[0]
raw_valid_df.shape[0]

raw_valid_df.head()

print(df.loc[df['exists']==False,:])

train_df = raw_train_df.groupby(['boneage_category', 'male']).apply(
  lambda x: x.sample(500, replace=True)).reset_index(drop=True)
valid_df, test_df = train_test_split(raw_valid_df,

  test_size=VALIDATION_FRACTION, random_state=2019)


fig, ax = plt.subplots()
ax = sns.distplot(test_df['boneage'], bins=10)
ax.set(xlabel='Boneage (months)', ylabel='Density',
    title='Boneage test distribution');

fig, ax = plt.subplots()
ax = sns.distplot(train_df['boneage'], bins=10)
ax.set(xlabel='Boneage (months)', ylabel='Density',
    title='Boneage training distribution');

import keras
optim = keras.optimizers.Nadam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.0003)

BATCH_SIZE_TEST = len(test_df) // 3
STEP_SIZE_TEST = 3
STEP_SIZE_TRAIN = len(train_df) // BATCH_SIZE_TRAIN
STEP_SIZE_VALID = len(valid_df) // BATCH_SIZE_VAL

def gen_2inputs(imgDatGen, df, batch_size, seed, img_size):
    gen_img = imgDatGen.flow_from_dataframe(dataframe=df,
        x_col='file', y_col='boneage_zscore',
        batch_size=batch_size, seed=seed, shuffle=True, class_mode='other',
        target_size=img_size, color_mode='rgb',
        drop_duplicates=False)
    
    gen_gender = imgDatGen.flow_from_dataframe(dataframe=df,
        x_col='file', y_col='gender',
        batch_size=batch_size, seed=seed, shuffle=True, class_mode='other',
        target_size=img_size, color_mode='rgb',
        drop_duplicates=False)
    
    while True:
        X1i = gen_img.next()
        X2i = gen_gender.next()
        yield [X1i[0], X2i[1]], X1i[1]

def test_gen_2inputs(imgDatGen, df, batch_size, img_size):
    gen_img = imgDatGen.flow_from_dataframe(dataframe=df,
        x_col='file', y_col='boneage_zscore',
        batch_size=batch_size, shuffle=False, class_mode='other',
        target_size=img_size, color_mode='rgb',
        drop_duplicates=False)
    
    gen_gender = imgDatGen.flow_from_dataframe(dataframe=df,
        x_col='file', y_col='gender',
        batch_size=batch_size, shuffle=False, class_mode='other',
        target_size=img_size, color_mode='rgb',
        drop_duplicates=False)
    
    while True:
        X1i = gen_img.next()
        X2i = gen_gender.next()
        yield [X1i[0], X2i[1]], X1i[1]

train_idg = ImageDataGenerator(zoom_range=0.2,
                               fill_mode='nearest',
                               rotation_range=25,  
                               width_shift_range=0.25,  
                               height_shift_range=0.25,  
                               vertical_flip=False, 
                               horizontal_flip=True,
                               shear_range = 0.2,
                               samplewise_center=False, 
                               samplewise_std_normalization=False)

val_idg = ImageDataGenerator(width_shift_range=0.25, height_shift_range=0.25, horizontal_flip=True)

train_flow = gen_2inputs(train_idg, train_df, BATCH_SIZE_TRAIN, SEED, IMG_SIZE)

valid_flow = gen_2inputs(val_idg, valid_df, BATCH_SIZE_VAL, SEED, IMG_SIZE)

test_idg = ImageDataGenerator()

test_flow = test_gen_2inputs(test_idg, test_df, 789, IMG_SIZE)

i1 = Input(shape=(299, 299, 3), name='input_img')
i2 = Input(shape=(1,), name='input_gender')
base = InceptionV3(input_tensor=i1, input_shape=(299, 299, 3), include_top=False, weights=None)

feature_img = base.get_layer(name='mixed10').output
feature_img = AveragePooling2D((2, 2))(feature_img)
feature_img = Flatten()(feature_img)
feature_gender = Dense(32, activation='relu')(i2)
feature = concatenate([feature_img, feature_gender], axis=1)

# feature = feature_img
o = Dense(1000, activation='relu')(feature)
o = Dense(1000, activation='relu')(o)
o = Dense(1)(o)
model = Model(inputs=[i1, i2], outputs=o)
optimizer = Adam(lr=1e-3)
model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mae'])

print('==================================================')
print('======= Training Model on Boneage Dataset ========')
print('==================================================')

#print('current time: %s' % str(datetime.now()))

model.summary()

#filepath='/gdrive/My Drive/incept30ep.h5'
#checkpoints=ModelCheckpoint(filepath,monitor='loss',verbose=1,save_best_only=True,mode='min')
#callbacks_list=[checkpoints]

#checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,save_best_only=True, mode='min', save_weights_only=True)

reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8,patience=10, verbose=1, mode='auto', min_delta=0.0001, cooldown=5,min_lr=0.00006)
early = EarlyStopping(monitor="val_loss", mode="min", patience=8)
callbacks_list = [ early, reduceLROnPlat]

import tensorflow as tf

from tensorflow.keras.models import load_model
new_model=load_model("C:\\Users\\Khushi\\Downloads\\incept30ep.h5", custom_objects = { "tf": tf })

#model_history =new_model.fit_generator(generator=train_flow,
 #                                   steps_per_epoch=STEP_SIZE_TRAIN, validation_data=valid_flow,
  #                                  validation_steps=STEP_SIZE_VALID, epochs=30)
#new_model.save('/gdrive/My Drive/incept30ep5.h5')

"""# New Section"""

'''
p=[7049,12447]
test=df.loc[df['id'].isin(p)]
test_flow1 = test_gen_2inputs(test_idg, test, 2, IMG_SIZE)
test_X,test_Y=next(test_flow1)
'''
test_X,test_Y=next(test_flow)

plt.style.use("dark_background")
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'DejaVu Sans'
print(boneage_div)
#print(model.predict(test_X, batch_size = 263, verbose = True))
print(boneage_mean)
pred_Y = boneage_div*new_model.predict(test_X, batch_size = 263, verbose = True)+boneage_mean
test_Y_months = boneage_div*test_Y+boneage_mean
'''
ord_idx = np.argsort(test_Y)
ord_idx = ord_idx[np.linspace(0, len(ord_idx)-1, 4).astype(int)] # take 8 evenly spaced ones
fig, m_axs = plt.subplots(2, 2, figsize = (8, 8))
for (idx, c_ax) in zip(ord_idx, m_axs.flatten()):
    cur_img = test_X[0][idx:(idx+1)]
    c_ax.imshow(cur_img[0, :,:,0], cmap = 'bone')
    
    c_ax.set_title('Age: %2.1fY\nPredicted Age: %2.1fY' % (test_Y_months[idx]/42.0, 
                                                           pred_Y[idx]))
    c_ax.axis('off')
#fig.savefig('trained_img_predictions.png', dpi = 300)
'''

from sklearn.metrics import mean_absolute_error
mean_absolute_error(test_Y_months,pred_Y)
'''
p=pred_Y.reshape(-1,1)
print(p.shape)
p=p.flatten()
p.shape
#print(p)
type(p)

b=test_df['id']
pth=test_df['file']
b2=test_df['boneage']

#gender1=df['male']
a=abs(p-test_Y_months)
#print(a)
df=pd.DataFrame()
df['id']=b
df['act']=test_Y_months
df['pred']=p
a.flatten()
df['diff']=a
#df['path']=pth
#df['gender1']=gender1
#df['bonage1']=test_Y_months
#df['bonage2']=b2
#df.head()
sorted=df.sort_values('diff')
df=sorted
print("best cases")
#print(sorted.head(20))
print("worst cases")
print(sorted.tail(20))
df.to_csv('/gdrive/My Drive/epoch140(127images).csv')
'''

import pandas as pd
act=pd.DataFrame(test_Y_months)
p=pd.DataFrame(pred_Y)
diff=pd.DataFrame(abs(act-p))

print(diff)


diff.describe()